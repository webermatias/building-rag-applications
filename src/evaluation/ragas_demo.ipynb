{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "85a8977f-258c-4478-b604-273afbed2b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "envs = load_dotenv(find_dotenv(), override=True)\n",
    "\n",
    "import time\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import os\n",
    "from rich import print\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from openai import OpenAI\n",
    "from ragas.testset.generator import TestsetGenerator\n",
    "from ragas.testset.evolutions import simple, reasoning, multi_context, multi_context_question_prompt\n",
    "from ragas.metrics import (\n",
    "context_relevancy,\n",
    "answer_correctness,\n",
    "answer_relevancy,\n",
    "faithfulness,\n",
    "context_recall,\n",
    "context_precision)\n",
    "from ragas import evaluate\n",
    "\n",
    "from litellm import ModelResponse\n",
    "from src.database.database_utils import get_weaviate_client\n",
    "from src.llm.llm_interface import LLM\n",
    "from src.llm.llm_utils import get_token_count\n",
    "from src.llm.prompt_templates import question_answering_prompt_series, huberman_system_prompt\n",
    "from app_features import generate_prompt_series\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from datasets import Dataset\n",
    "litellm.set_verbose = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "ce30d7f7-839c-4f9e-8d39-cb6d27cbc1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c0910d-9040-4def-9a62-f3a5682e778e",
   "metadata": {},
   "source": [
    "### Test Set Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "4b9be47e-a0e2-487d-ae49-6b62903b22ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = get_weaviate_client()\n",
    "turbo = LLM(model_name='gpt-3.5-turbo-0125')\n",
    "claude = LLM('claude-3-opus-20240229', os.environ['ANTHROPIC_API_KEY'])\n",
    "gpt4 = LLM(model_name='gpt-4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "33cb7ce0-c6cf-41e5-b5f2-1c85c3f69225",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\"Give a brief explanation of how brain neuroplasticity works\",\n",
    "             \"What is the role of dopamine in the body\",\n",
    "             \"What is a catecholimine\",\n",
    "             \"What does Jocko have to say about leadership\",\n",
    "             \"What does Fridman think about the evolution of AI\", \n",
    "             \"Who is the host of the Huberman Labs podcast\",\n",
    "             \"Why do people make self-destructive decisions\",\n",
    "             \"Provide better sleep protocol in list format\",\n",
    "             \"What are the topcis that Lex Fridman discusses\",\n",
    "             \"Is there a generally positive outlook on the future of AI\",\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "419530a7-ad47-4df8-b34e-8278ce6fb75d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Huberman_minilm_512'"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection_names = client.show_all_collections()\n",
    "collection_names[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "766259b5-ab80-4960-9951-513258cad40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer_bundle(client, answer_llm, ground_truth_llm, collection_name, query):\n",
    "    '''\n",
    "    Returns answer, ground truth and associated context from a single query.\n",
    "    '''\n",
    "    def format_llm_response(response: ModelResponse) -> str:\n",
    "        return response.choices[0].message.content\n",
    "\n",
    "    #1st-stage retrieval (get contexts)\n",
    "    context = client.hybrid_search(query, collection_name, \n",
    "                                   query_properties=['content', 'title', 'short_description'],\n",
    "                                   limit=3, \n",
    "                                   return_properties=['content', 'guest', 'short_description'])\n",
    "    #create contexts from content field\n",
    "    contexts = [d['content'] for d in context]\n",
    "    \n",
    "    #generate assistant message prompt\n",
    "    assist_message = generate_prompt_series(query, context, summary_key='short_description')\n",
    "\n",
    "    #generate answers from model being evaluated\n",
    "    answer = format_llm_response(answer_llm.chat_completion(huberman_system_prompt, assist_message))\n",
    "\n",
    "    #create ground truth answers\n",
    "    ground_truth = format_llm_response(ground_truth_llm.chat_completion(huberman_system_prompt, assist_message))\n",
    "        \n",
    "    return query, contexts, answer, ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "c08af3e3-0f0e-4536-94f9-759c75a07bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def capture_data(client,\n",
    "                 answer_llm: LLM,\n",
    "                 ground_truth_llm: LLM,\n",
    "                 collection_name: str, \n",
    "                 questions: list[str]\n",
    "                 ) -> tuple[list[list[str]], list[str], list[str]]:\n",
    "    contexts = []\n",
    "    answers = []\n",
    "    ground_truths = []\n",
    "\n",
    "    def format_llm_reponse(response: ModelResponse) -> str:\n",
    "        return response.choices[0].message.content\n",
    "        \n",
    "    for i, q in enumerate(tqdm(questions)):\n",
    "        context = client.hybrid_search(q, collection_name, \n",
    "                                       query_properties=['content', 'title', 'short_description'],\n",
    "                                       limit=3, \n",
    "                                       return_properties=['content', 'guest', 'short_description'])\n",
    "        #create contexts from content field\n",
    "        contexts.append([d['content'] for d in context])\n",
    "        \n",
    "        #generate assistant message prompt\n",
    "        assist_message = generate_prompt_series(q, context, summary_key='short_description')\n",
    "\n",
    "        #generate answers from model being evaluated\n",
    "        print('Making Answer LLM call...')\n",
    "        answer = answer_llm.chat_completion(huberman_system_prompt, assist_message)\n",
    "        answers.append(format_llm_reponse(answer))\n",
    "\n",
    "        #create ground truth answers\n",
    "        print('Making Ground Truth LLM call...')\n",
    "        ground_truth = ground_truth_llm.chat_completion(huberman_system_prompt, assist_message)\n",
    "        ground_truths.append(format_llm_reponse(ground_truth))\n",
    "        \n",
    "    return contexts, answers, ground_truths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "d37acb4e-7769-430c-aa94-48d02ca0a682",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import ceil\n",
    "from time import sleep\n",
    "\n",
    "def capture_data_threaded(questions: list[str], \n",
    "                          client, \n",
    "                          answer_llm, \n",
    "                          ground_truth_llm, \n",
    "                          collection_name, \n",
    "                          batch_size: int=5, \n",
    "                          disable_internal_tqdm: bool=False):\n",
    "    total = len(questions)\n",
    "    progress = tqdm('Queries', total=total, disable=disable_internal_tqdm)\n",
    "    data = []\n",
    "    batches = ceil(total/batch_size)\n",
    "    for i in range(batches):\n",
    "        batch = questions[i*batch_size:(i+1)*batch_size]\n",
    "        with ThreadPoolExecutor(max_workers=os.cpu_count() * 2) as executor:\n",
    "            futures = [executor.submit(get_answer_bundle, client, answer_llm, ground_truth_llm, collection_name, query) for query in batch]\n",
    "            for future in as_completed(futures):\n",
    "                progress.update(1)\n",
    "                data.append(future.result())\n",
    "        print(f\"Finished with batch {i+1}, taking a break...\")\n",
    "    queries = [d[0] for d in data]\n",
    "    contexts = [d[1] for d in data]\n",
    "    answers = [d[2] for d in data]\n",
    "    ground_truths = [d[3] for d in data]\n",
    "    return queries, contexts, answers, ground_truths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "7c407138-972d-4464-883c-2a4cd1ef536e",
   "metadata": {},
   "outputs": [],
   "source": [
    "twenty_questions = questions * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "7f9452ca-c0c7-4b86-9f6a-25eda8ff7e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:11<00:00,  1.66s/it]"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Finished with batch <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, taking a break<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Finished with batch \u001b[1;36m1\u001b[0m, taking a break\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:11<00:00,  2.33s/it]\n"
     ]
    }
   ],
   "source": [
    "data = capture_data_threaded(questions, client, turbo, gpt4, collection_names[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "eff7e89c-4844-4729-b963-7554894e3cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                             | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Making Answer LLM call<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Making Answer LLM call\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Making Ground Truth LLM call<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Making Ground Truth LLM call\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████████████████████▍                                                                                             | 1/5 [00:05<00:23,  5.99s/it]"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Making Answer LLM call<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Making Answer LLM call\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Making Ground Truth LLM call<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Making Ground Truth LLM call\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|██████████████████████████████████████████████▊                                                                      | 2/5 [00:14<00:22,  7.58s/it]"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Making Answer LLM call<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Making Answer LLM call\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Making Ground Truth LLM call<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Making Ground Truth LLM call\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████████████████████████████████████████████████████████████████████▏                                              | 3/5 [00:22<00:15,  7.60s/it]"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Making Answer LLM call<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Making Answer LLM call\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Making Ground Truth LLM call<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Making Ground Truth LLM call\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|█████████████████████████████████████████████████████████████████████████████████████████████▌                       | 4/5 [00:29<00:07,  7.38s/it]"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Making Answer LLM call<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Making Answer LLM call\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Making Ground Truth LLM call<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Making Ground Truth LLM call\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:37<00:00,  7.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 535 ms, sys: 12.6 ms, total: 548 ms\n",
      "Wall time: 37.5 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "contexts, answers, ground_truths = capture_data(client, turbo, gpt4, collection_name, questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "3768e266-3980-4354-827a-888327bf1adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_dataset(questions: list[str],\n",
    "                   contexts: list[list[str]],\n",
    "                   answers: list[str], \n",
    "                   groundtruth: list[str]\n",
    "                   ):\n",
    "    data_samples = {\n",
    "                    'question': questions,\n",
    "                    'contexts': contexts,\n",
    "                    'answer': answers,\n",
    "                    'ground_truth': groundtruth\n",
    "                    }\n",
    "    return Dataset.from_dict(data_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "91b25048-0206-485f-b596-ca3a562a5aaf",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[\"Catecholamines are things like dopamine, epinephrine, norepinephrine. These are chemicals in your nervous system and body that promote states of alertness. Dopamine, of course, part of the reward and motivation pathways. They explored the levels of these molecules in blood, in plasma, during and after this breathing protocol. And it was interesting, as I mentioned before, epinephrine showed robust increases compared to the control group. Norepinephrine, significant increases occurred in the breathing group, but in the cyclic hyperventilation retention breathing group, of course, but less so. And dopamine levels actually dropped somewhat. But this is very interesting because there's a new and emerging literature, largely from ISA, A-Y-S-A, Roll's lab in Israel. What her laboratory has shown is that motivational state and mindset has a powerful impact on various aspects of the immune system that were thought to be independent of the brain and mind and thinking. So this brings us back to something that we discussed at the very beginning of this episode, which is that, you know, 20, 30 years ago, the idea that you could heal the body with the mind was considered kind of quackery. I think that there was an intervening period up until now where people might've said, sure, if you're stressed out, it's going to make things worse. I mean, I think everyone agrees that stress makes everything worse at some level. Outcomes to neurodegeneration, performance in physical endeavors and mental endeavors. If stress is too high for too long, people experience different challenges and essentially every major psychiatric disorder, everything suffers. But in the short term, stress can actually be beneficial in the ways that we just described. And stress, if we break it down, is really a neurochemical state, right? It's the release of these catecholamines. And what Issa Rolls' laboratory has shown is that when the so-called dopamine system, and at several episodes I described there multiple dopamine systems, but the so-called mesolimbic reward pathway involving areas like the nucleus accumbens, et cetera, when the reward system that's associated with dopamine and norepinephrine is activated, you see incredible effects, including for instance, highly significant reduction in tumor size in cancers. Now, why would that be?\",\n",
       "  \"And what we've done in the last 10 years is to try to understand what does that pattern come from? And if we were to look at each individual site from that part of the brain, what would we see? What parts of words are being coded by electrical activity in those parts of the brain? Remember, the cortex is using electrical activity to transmit information and do analysis. And what we're doing is we're eavesdropping on this part of the brain as it's processing speech to try to understand what each individual site is doing. And what are those sites doing? Or could you give us some examples of what those sites are doing? So for instance, are they sites that are specific for, or we could say even listening for consonants or for vowels or for inflection or for emotionality. What's in there? What makes these cells fire? Yeah, what gets them excited? What gets them going is hearing speech. In particular, there are some of these really focal sites, again, just on the order of millimeter or at some level, single neurons that are tuned to consonants. Some are tuned to vowels. Some are tuned to particular features of consonants. What I mean by that are different categories of consonants. There's a class of consonants that we call plosive consonants. There's a little bit of linguistic jargon, but I'm going to make a point here with that is that certain classes of sounds, when you make them, it requires you to actually close your mouth temporarily. Now I'm going to be thinking about this. So plosive, like saying the word plosive requires that. Exactly. So what's cool about that is that we actually have no idea what's going on in our mouth when we speak we really have no idea some people definitely have no idea well not just like in terms of what you're saying sometimes but actually like how you're actually moving right you know the different parts of vocal track and I have a feeling if we actually required understanding we would never be able to speak because it's so complex. It's such a complex feat. Some people would say it's the most complex motor thing that we do as a species is speaking, not the extreme feats of acrobatics or athleticism, but speaking. Especially when one observes opera or people who freestyle rappers.\",\n",
       "  \"You know, way at the outset of the podcast, you asked me kind of like, what are the obstacles to longevity? And that got us down a path of some very black and white things. But when I look at a patient, I create a dashboard. And the dashboard is what are all the things that are a threat to every component of your longevity, both lifespan and healthspan. We talked about a bunch of those things. So what is your risk for atherosclerosis and what are we doing about it? What is your risk for cancer? What are we doing about it? What is your risk for neurodegeneration? What are we doing about it? What is your risk for accidental death? What are we doing about it? What is your risk for physical decline? What are we doing about it? And one of those things is, what is your risk of emotional health or poor emotional health and what are we doing about it? So when I do that exercise for me, which I do, right? I mean, I have that spreadsheet laid out for me and I know where my factors line up. And interestingly, despite my family history being horrible for atherosclerosis, it's like sixth on my list. Because, I mean, basically I intervened early. I have a clear understanding of the pathophysiology and I'm doing everything to the maximum. So I'm actually very confident I will die with and not from atherosclerosis. But the top thing on my list is actually emotional health. That's the one that is the hardest for me to manage. And it's the easiest to get out of balance and it creates the most pain in my life. So that's a long answer to why I felt this needed to be in here. Well, in the book, you go into very honest detail about some of your journeys through and challenges with emotional health and paths to overcoming those. Maybe we'll get into those a bit, but before we do, how should we define emotional health? This to me seems like one of the most difficult areas to calibrate oneself. Like even just measuring emotion is tricky. Language is the dissection tool for psychologists, psychiatrists, and indeed for all of us. You know, how are you doing today? Great. Or I'm miserable or I'm depressed.\"],\n",
       " [\"The whole brain acts as a buffer, and the frontal lobe can call up any part of the brain and keep that part of the brain active as it's trying to hold this information in line. So the mechanism for working memory is just this persistent neural activity within the frontal lobes. And so then the question is, what does dopamine do? Well, dopamine is one of the neuromodulators that are made in the brainstem and it projects up to different parts of the brain. There's a system that goes up into what we call the basal ganglia, which is important for motor function. And there's another dopaminergic system that goes up to the frontal lobes. And what was discovered was that if you deplete dopamine, working memory drops. You get a significant impairment in working memory if you deplete dopamine. And if you replace it, then your working memory will be improved. And so dopamine seems to be a modulator to help this persistent activity stay persistent during the time that you need to keep this information in mind. Am I reaching too far to draw an analogy between dopamine's role in working memory, that is to keep information online, and the other established role of dopamine, which is for movement, for the generation of smooth movement, as evidenced by conditions like Parkinson's, where people lack dopaminergic neurons or have damage to dopaminergic neurons and have challenges in generating smooth movement. What I'm essentially asking is, can we think of dopamine as facilitating physical movement through one circuit, but also kind of mental movement, thought movement? And I'm thinking for those just listening and not watching, I'm kind of rubbing my index and middle finger against my thumb. So just keeping something online, it's sort of a movement of thought or information, and then you kind of chuck it away and bring about the next information. Is that appropriate? Yeah, I think that's a good way of thinking about it. And one might wonder, well, how can dopamine be important for memory, but also be important for movement? And it's really simple. It's just that it's acting on different circuits. The neurons that go to the motor areas that carry dopamine will, when dopamine is expressed there and boosted there, then it will be involved in movement. And lack of dopamine in the basal ganglia will lead to neurological disorders like Parkinson's disease that has severe movement difficulty.\",\n",
       "  \"In the nervous system, what this means is that dopamine release changes the probability that certain neural circuits will be active and that other neural circuits will be inactive, okay? So it modulates a bunch of things all at once. And that's why it's so powerful at shifting, not just our levels of energy, but also our mindset, also our feelings of whether or not we can or cannot accomplish something. So how does dopamine work and what does it do? Well, first of all, it is not just responsible for pleasure. It is responsible for motivation and drive, primarily at the psychological level, also for craving. Those three things are sort of the same, motivation, drive, and craving. It also controls time perception, and we will get deep into how dopamine can modulate time perception and how important it is that everybody be able to access increases in dopamine at different timescales. This turns out to be important to not end up addicted to substances, but it also turns out to be very important to sustain effort and be a happy person over long periods of time, which I think most everybody wants. It certainly is adaptive in life to be able to do that. Dopamine is also vitally important for movement. I'll explain the neural circuits for dopamine and mindset and dopamine in movement in a moment, but in diseases like Parkinson's or Lewy's body's dementia, which is similar to Parkinson's in many ways, there's a depletion or death of dopamine neurons at a particular location in the brain, which leads to shaky movements, challenges in speaking, challenges in particular in initiating movement. And because dopamine is depleted elsewhere too, people with Parkinson's and Lewy's, excuse me, Louie body dementia also experience drops in motivation and affect, meaning mood. They tend to get depressed and so on. When those people are properly treated, they can, not always, but they can recover some fluidity of movement, some ability to initiate movement. And almost without question, those people feel better psychologically, not just because they can move, but also because dopamine impacts mood and motivation. So what are the underlying neural circuits? For those of you that are not interested in biology and specific nomenclature, you can tune out now if you want, but it's actually pretty straightforward. You have two main neural circuits in the brain that dopamine uses in order to exert all its effects.\",\n",
       "  \"Dopamine is a molecule of motivation and anticipation. To illustrate how dopamine works, I want to highlight some very important work largely carried out by the laboratory of a guy named Wolfram Schultz. The Schultz Laboratory has done dozens of excellent experiments on the dopamine system and have identified something called reward prediction error. Although in some sense, you can think about it as reward prediction variance, changes in the levels of dopamine, depending on whether or not you expect a reward and whether or not you get the reward. So I'm going to make this very simple. Dopamine is released into the brain and body and generally makes us feel activated and motivated and as if we have energy to pursue a goal. And it is released into the brain and body in anticipation of a reward. Measurements of dopamine have been made in animals and humans. And what you find is that when we anticipate a reward, dopamine is released. We will put in the work to achieve that reward. That work could be mental work or physical work, but when the reward arrives, dopamine levels drop back down to baseline. That's right. When we receive a reward, dopamine levels go back down to baseline. So the way to envision this is you can just imagine a sort of increase in dopamine as we anticipate something, we're working towards it, we're working towards a goal, we're excited about seeing somebody or meeting somebody or receiving some reward, and then the reward comes and dopamine goes down. Now that's all fine and good, but there is a way to get much more dopamine out of that process and therefore a way to have much more motivation, energy, and focus, because those are the consequences of elevated dopamine. The way to do that is to not deliver the reward on an expected schedule. So experiments have been done where there's an anticipation of a reward, there's work, and then the reward only arrives every other or every third bout of work, okay? So this would be like getting a pat on the head if you're a dog or perhaps a child or an adult, or getting a monetary reward only for every third project or every third race that you win. Pick any kind of goal. It doesn't matter. These molecules don't care about what you're pursuing. They are a common currency of different types of activities. That's a regular reward schedule, and it will not alter the pattern of dopamine release that I described before.\"],\n",
       " [\"And in order to understand that process, we really have to understand something that might at first seem totally divorced from neuroplasticity, but actually lies at the center of neuroplasticity. And for any of you that are interested in changing your nervous system so that something that you want can go from being very hard or seem almost impossible and out of reach to being very reflexive, this is especially important to pay attention to. Plasticity in the adult human nervous system is gated, meaning it is controlled by neuromodulators. These things that we talked about earlier, dopamine, serotonin, and one in particular called acetylcholine are what open up plasticity. They literally unveil plasticity and allow brief periods of time in which whatever information, whatever thing we're sensing or perceiving or thinking, or whatever emotions we feel can literally be mapped in the brain such that later it will become much easier for us to experience and feel that thing. Now, this has a dark side and a positive side. The dark side is it's actually very easy to get neuroplasticity as an adult through traumatic or terrible or challenging experiences. But the important question is to say, why is that? And the reason that's the case is because when something very bad happens, there's the release of two sets of neuromodulators in the brain, epinephrine, which tends to make us feel alert and agitated, which is associated with most bad circumstances, and acetylcholine, which tends to create a even more intense and focused perceptual spotlight. Remember earlier, we were talking about perception and how it's kind of like a spotlight. Acetylcholine makes that light particularly bright and particularly restricted to one region of our experience. And it does that by making certain neurons in our brain and body active much more than all the rest. So acetylcholine is sort of like a highlighter marker upon which neuroplasticity then comes in later and says, wait, which neurons were active in this particularly alerting phase of whatever day or night, whenever this thing happened to happen. So the way it works is this, you can think of epinephrine as creating this alertness and this kind of unbelievable level of increased attention compared to what you were experiencing before. And you can think of acetylcholine as being the molecule that highlights whatever happens during that period of heightened alertness.\",\n",
       "  \"Yeah, okay. So he's a hero and I'm his student. But let's talk about Tommy for a sec. So Tommy, for a long time, he did magic that magicians did not know how it works. It was so devious that even magicians did not know how it works. And at some point, he released some DVDs that teach his magic. And the trick is very simple. He borrows someone's watch, it disappears, and there's a table right next to him with a little box and a ribbon. And he literally grabs the ribbon, so he never touches the box, lifts the box, gives it to somebody. He opens it. Inside, there an alarm clock. They unscrew the alarm clock and inside is their watch. No. I mean, yes. Yes. But even magicians who saw that, they go, I have no idea how it's done. No idea. And then I remember watching the explanation for the first time. And I was thinking that the method was by far more interesting, intriguing, revealing, just beautiful. It made the trick less. Like I said, you should perform the explanation. Don't perform the trick. Perform the explanation. And I broke the rules of magic. Like my non-magician friends will come over and say, let me share something. And I show them the trick and they go, wow, that's amazing. Let me show the explanation. And their mind was blown. Are you willing to share a little bit of what the explanation is or is that not? No, no. Okay. But I will explain a little bit. So the explanation was that he revealed that he's an engineer, that he can build props that are like ingenious. Again, I'm going around it, but at some point, the person who opens the box is doing part of the trick and he doesn't know it. He's creating the trick, but he doesn't know he's contributing something to it. And it's just beautiful. Metaphorically, symbolically, it hits so many levels at least. And that planted a seed in my mind. I want to create an effect that the method is prettier than the trick itself.\",\n",
       "  \"We're going to talk about how to access neuroplasticity, depending on how old you are, and depending on the specific types of changes that you're trying to create. This is a topic for which there are lots of tools, as well as lots of biological principles that we can discuss. So let's get started. Most people are familiar with the word neuroplasticity. It's sometimes also called neuroplasticity. Those are the same thing. So if I say neuroplasticity or neuroplasticity, I'm referring to the same process, which is the brain and nervous system's ability to change itself. And there are a lot of reasons why the nervous system would do this. It could do it in response to some traumatic event. It could, for instance, create a sense of fear around a particular place or a fear of automobiles or planes. It could also occur when something positive happens, like the birth of our first child, or when our puppy does something amusing, or we see an incredible feat of performance in athleticism. The word neuroplasticity means so many things to so many different people that I thought it would be important to just first put a little bit of organizational logic around what it is and how it happens. Because nowadays, if you were to go online and Google the word neuroplasticity, you would find hundreds of thousands of references, scientific references, as well as a lot of falsehoods about what neuroplasticity is and how to access it. As I mentioned before, we're going to talk about the science of it, and we're going to talk about the tools that allow you to engage this incredible feature of your nervous system. And that's the first point, which is that all of us were born with a nervous system that isn't just capable of change, but was designed to change. When we enter the world, our nervous system is primed for learning. The brain and nervous system of a baby is wired very crudely. The connections are not precise. And we can see evidence of that in the fact that babies are kind of flopping there like a kind of a little potato bug with limbs. They can't really do much in terms of coordinated movement. They certainly can't speak and they can't really do anything with precision. And that's because we come into this world over-connected. We have essentially wires.\"],\n",
       " [\"Welcome to the Huberman Lab Podcast, where we discuss science and science-based tools for everyday life. I'm Andrew Huberman, and I'm a professor of neurobiology and ophthalmology at Stanford School of Medicine. Today, my guest is Jocko Willink. Jocko Willink is a retired Navy SEAL, an author of numerous important books on leadership and team dynamics, and the host of the Jocko podcast. During his 20-year career with the US Navy, Jocko served with SEAL Team 3 as commander of Task Unit Bruiser in Ramadi, Iraq, and elsewhere in the Middle East, as well as deployments in Asia and Europe. After retiring from the Navy, Jocko used his experience and knowledge gleaned from his time in the SEAL teams as a way to develop tools that anybody can use to develop their leadership skills, both for leading themselves and for leading others. That took the form of several important books, the first of which was published in 2015 and is entitled Extreme Ownership, How US Navy SEALs Lead and Win. He has also authored several books for kids about leadership, personal development, and how to navigate various aspects of life. I've read both Extreme Ownership and The Way of the Warrior Kid, and I found them to be immensely useful in terms of actionable information and understanding of oneself and different kinds of relationships, both in and out of the workplace. Typically guests on the Huberman Lab Podcast are scientists and or clinicians. It was some time ago that I was a guest on the Jocko podcast. And during the course of our conversation on his podcast, we quickly realized that many of the science-based tools that my laboratory has focused on and that I've used over the years and shared on the Huberman Lab Podcast had direct overlap and parallel with many of the tools that Jocko and other members of the SEAL teams had arrived at independently, that is without knowledge of the underlying science. And in fact, he had many more tools that he had incorporated during his years in the SEAL teams, as well as in business leadership, in family and elsewhere in life that I quickly realized it would be an enormously valuable conversation to have him on this podcast in order to share those tools with the general public.\",\n",
       "  \"And somebody asked me, somebody said, Hey, I'm going to bootcamp soon. What advice do you have for me? And I wrote back, enjoy. Boom. And like you said, I mean, it's Twitter. I'm'm responding to a bunch of people and then somebody else chimed in and said you know might as well not even answer jocko that's not helping this guy at all and look look at your face for those of you that are watching uh your face just got a little bit mad right you got a little bit defensive for me yeah i well that i think that's my nature i don't like seeing other people sort of attacked i I think that's just my nature. I had a split second of, who the hell is this guy? And then I said, you know what? He's right. And then I tweeted again, back thing. I said, sorry, man, you're right. What I should have said was, hey, read the book, Leadership Strategy and Tactics. It's a good book for someone that is going to be in an environment that's going to be challenging and we're going to be faced with leadership challenges. And enjoy boot camp because if your mindset is this sucks and this is terrible, it's going to be terrible and it's going to suck. And if you go with a mindset of, hey, this is a cool experience and I should enjoy it, you're going to have a much better time. That's my full answer. I'm sorry I didn't give you. And it's perfectly fine. Like that guy was right to critique me. And he was right in saying that. And there was a bunch of, what's funny is a bunch of other people came to my defense and said, this guy, that's really great. And so, but my point is instead of me getting defensive and crazy and letting it drive me crazy, open my mind a little bit, listen to what they have to say, except that there's got to be some level of truth in it. And there was, I gave a guy a very, very terse response and I could have expanded on it more. And I did no big deal. Good times. those that are usually anywhere from five to 20 hours of prep.\",\n",
       "  \"And this is what, from a leadership perspective, you have to pay attention to. So when you're a leader in any organization, you're basically in charge of a mob. When it comes to what their morale is, they're a mob and they feed off of each other, just like a mob riding in the streets going, oh, we can break this window. Let's break all the windows. And they move this mob mentality. And that happens with morale inside of a team. And you as a leader can't get caught up with the mob. You can't let that happen. You have to detach yourself from the mob mentally so that you don't get caught up in their emotions and their morale. Because if you get caught up in their emotions and you get caught up in their morale, you can't correct it. So we go out on a mission. The mission goes great. We get into a gunfight, kill a couple bad guys. Everyone's okay. High fives. Everyone's feeling great. You come back to base. Hey, we don't need to debrief. That was perfect. Hey, we don't need to get our gear maintained. We can just go to bed. We're awesome. That's when the leader has to say, oh, we've got the mob and the mob is becoming slightly arrogant. Hey guys, real quick, that was a good op, but there's some things we could improve on. You got to bring that mob back and bring them back to center line. Same thing in the other direction. You go out on an operation, it doesn't go well. You go out on an operation, you take casualties. Now you come back to base. You see guys moping around. You see the spirit starting to break. And same thing. If you're part of that mob, you'll be with them. Your morale will be breaking. Your spirit will be breaking. You got to look at them and say, oh, I see what's happening. Hey guys, listen up. That was tough. Didn't go the way we wanted it to go. We need to learn some lessons. Here's some things I can do better. What can we do better to make sure that that never happens again?\"],\n",
       " [\"Pamela McCordick said AI was the ancient wish to forge the gods or was born as an ancient wish to forge the gods. So I think at the big philosophical level, it's our longing to create other intelligent systems, perhaps systems more powerful than us. At the more narrow level, I think it's also a set of tools that are computational, mathematical tools to automate different tasks. And then also it's our attempt to understand our own mind. So build systems that exhibit some intelligent behavior in order to understand what is intelligence in our own selves. So all those things are true. Of course, what AI really means is a community as a set of researchers and engineers, it's a set of tools, a set of computational techniques that allow you to solve various problems. There's a long history that approaches the problem from different perspectives. What's always been throughout one of the threads, one of the communities goes under the flag of machine learning, which is emphasizing in the AI space the task of learning. How do you make a machine that knows very little in the beginning, follow some kind of process, and learns to become better and better at a particular task? What's been most very effective in the recent about 15 years is a set of techniques that fall under the flag of deep learning. They utilize neural networks. What neural networks are, are these fascinating things inspired by the structure of the human brain very loosely, but they have, it's a network of these little basic computational units called neurons, artificial neurons. And they have, these architectures have an input and output. They know nothing in the beginning and they're tasked with learning something interesting. What that something interesting is usually involves a particular task. There's a lot of ways to talk about this and break this down. Like one of them is how much human supervision is required to teach this thing so supervised learning this broad category is the the neural network knows nothing in the beginning and then it's given a bunch of examples of uh in computer vision that would be examples of cats dogs cars traffic signs and then you're given the image and you're given the ground truth of what's in that image and when you get a large database of such image examples where you know the truth the the neural network is able to learn by example that's called supervised learning the question there's a lot of fascinating questions within that which is how do do you provide the truth?\",\n",
       "  \"That's very, people are very interested in because the more and more we rely on AI systems, like the Twitter recommender system, that AI algorithm, that's, I would say, impacting elections, perhaps starting wars or at least military conflict. That's that algorithm. We want to ask that algorithm, first of all, do you know what the hell you're doing? Do you know, do you understand the society level effects you're having? And can you explain the possible other trajectories? Like we would have that kind of conversation with a human. We want to be able to do that with an AI. And on my own personal level, I think it would be nice to talk to AI systems for stupid stuff, like robots when they fail to- Why do you fall down the stairs? Yeah, but not an engineering question, but almost like endearing question. Like I'm looking for, if I fell and you and I were hanging out, I don't think you need an explanation exactly what were the dynamic, like what was the underactuated system problem here? Like what was the texture of the floor or so on? Or like, what was the- No, I wanna know what you're thinking. That, or you might joke about like, you're drunk again, go home or something. Like there could be humor in it. That's an opportunity. Like storytelling isn't just explanation of what happened. It's something that makes people laugh, makes people fall in love, makes people dream and understand things in a way that poetry makes people understand things as opposed to a rigorous log of where every sensor was, where every actuator was. from the autistic person that is very much a catalog of action steps. It's like, how do you feel today? And they'll say, well, I got up and I did this, and then I did this and I did this. And it's not at all the way that a person who doesn't have autism spectrum disorder would respond. And the way you describe these machines has so much humanism or so much of a human and biological element. But I realized that we were talking about machines. I want to make sure that I understand if there's a distinction between a machine that learns, a machine with artificial intelligence and a robot. At what point does a machine become a robot?\",\n",
       "  \"I also see the human brain and I hope artificial intelligence systems as not just systems that solve problems or optimize a goal, but are also storytellers. I think there's a power to telling stories. We tell stories to each other. That's what communication is. Like when you're alone, that's when you solve problems. That's when it makes sense to talk about solving problems. But when you're a community, the capability to communicate, tell stories, share ideas in such a way that those ideas are stable over a long period of time, that's being a charismatic storyteller. And I think both humans are very good at this. Arguably, I would argue that's why we are who we are is we're great storytellers. And then AI, I hope, will also become that. So it's not just about being able to solve problems with a clear objective function. It's afterwards, be able to tell like a way better, like make up a way better story about why you did something or why you failed. So you think that robots and or machines of some sort are going to start telling human stories? Well, definitely. So the technical field for that is called explainable AI, explainable artificial intelligence, is trying to figure out how you get the AI system to explain to us humans why the hell it failed or why it succeeded. Or there's a lot of different sort of versions of this, or to visualize how it understands the world. That's a really difficult problem, especially with neural networks that are famously opaque. We don't understand in many cases why a particular neural network does what it does so well. And to try to figure out where it's going to fail, that requires the AI to explain itself. There's a huge amount of money, like there's a huge amount of money in this, especially from government funding and so on, because if you want to deploy AI systems in the real world, we humans at least want to ask it a question like, why the hell did you do that? Like in a dark way, why did you just kill that person? Right? Like if a car ran over a person, we want to understand why that happened. And now again, we're sometimes very unfair to AI systems because we humans can often not explain why very well. But that's the field of explainable AI.\"]]"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "22856fa7-c80d-4e44-b6e8-d93386d9e457",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = format_dataset(*data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "b51e5c51-cb1d-49d8-a34d-e6d7ca63d44d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>contexts</th>\n",
       "      <th>answer</th>\n",
       "      <th>ground_truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is a catecholimine</td>\n",
       "      <td>[Catecholamines are things like dopamine, epin...</td>\n",
       "      <td>A catecholamine is a type of neurochemical tha...</td>\n",
       "      <td>A catecholamine is a chemical in your nervous ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the role of dopamine in the body</td>\n",
       "      <td>[The whole brain acts as a buffer, and the fro...</td>\n",
       "      <td>The role of dopamine in the body is multifacet...</td>\n",
       "      <td>Dopamine plays multiple roles in the body, pri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Give a brief explanation of how brain neuropla...</td>\n",
       "      <td>[And in order to understand that process, we r...</td>\n",
       "      <td>Brain neuroplasticity is the brain and nervous...</td>\n",
       "      <td>Brain neuroplasticity refers to the brain and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What does Jocko have to say about leadership</td>\n",
       "      <td>[Welcome to the Huberman Lab Podcast, where we...</td>\n",
       "      <td>Jocko emphasizes the importance of detachment ...</td>\n",
       "      <td>Jocko Willink discusses several key aspects of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What does Fridman think about the evolution of AI</td>\n",
       "      <td>[Pamela McCordick said AI was the ancient wish...</td>\n",
       "      <td>Fridman believes that the evolution of AI invo...</td>\n",
       "      <td>Fridman views the evolution of AI as multiface...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0                            What is a catecholimine   \n",
       "1           What is the role of dopamine in the body   \n",
       "2  Give a brief explanation of how brain neuropla...   \n",
       "3       What does Jocko have to say about leadership   \n",
       "4  What does Fridman think about the evolution of AI   \n",
       "\n",
       "                                            contexts  \\\n",
       "0  [Catecholamines are things like dopamine, epin...   \n",
       "1  [The whole brain acts as a buffer, and the fro...   \n",
       "2  [And in order to understand that process, we r...   \n",
       "3  [Welcome to the Huberman Lab Podcast, where we...   \n",
       "4  [Pamela McCordick said AI was the ancient wish...   \n",
       "\n",
       "                                              answer  \\\n",
       "0  A catecholamine is a type of neurochemical tha...   \n",
       "1  The role of dopamine in the body is multifacet...   \n",
       "2  Brain neuroplasticity is the brain and nervous...   \n",
       "3  Jocko emphasizes the importance of detachment ...   \n",
       "4  Fridman believes that the evolution of AI invo...   \n",
       "\n",
       "                                        ground_truth  \n",
       "0  A catecholamine is a chemical in your nervous ...  \n",
       "1  Dopamine plays multiple roles in the body, pri...  \n",
       "2  Brain neuroplasticity refers to the brain and ...  \n",
       "3  Jocko Willink discusses several key aspects of...  \n",
       "4  Fridman views the evolution of AI as multiface...  "
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3cdac26b-90c3-4f51-bbb8-078c45756920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, q in enumerate(questions):\n",
    "#     print(f'Questions {i}: {q}')\n",
    "#     print(f'Context: {contexts[i][0]}')\n",
    "#     print(f'{contexts[i][1]}')\n",
    "#     print(f'{contexts[i][2]}')\n",
    "#     print()\n",
    "#     print('-'*100)\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "f7d45b83-01ff-4f2a-ba8e-c67628099919",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_harness(indexes: list[str], questions: list[str], batch_size: int=5):\n",
    "    start = time.perf_counter()\n",
    "    results = {}\n",
    "    metrics = [answer_correctness, answer_relevancy, context_relevancy, faithfulness]\n",
    "    for index in tqdm(indexes):\n",
    "        data = capture_data_threaded(questions, client, turbo, gpt4, index, batch_size, True)\n",
    "        dataset = format_dataset(*data)\n",
    "        evaluation = evaluate(dataset, metrics)\n",
    "        results[index] = evaluation\n",
    "    end = time.perf_counter() - start\n",
    "    print(f'Total Time for Evaluation: {round(end/60, 2)} minutes')\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "a6e26d07-bda9-4f37-bec6-05e69d7bfa20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "1a06c4ee-b64b-44c1-a914-e962fe1ccbba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                             | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Finished with batch <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, taking a break<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Finished with batch \u001b[1;36m1\u001b[0m, taking a break\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Finished with batch <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, taking a break<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Finished with batch \u001b[1;36m2\u001b[0m, taking a break\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab9f40ccb3894263ac151c1464c593f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No statements were generated from the answer.\n",
      " 33%|███████████████████████████████████████                                                                              | 1/3 [00:35<01:10, 35.48s/it]"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Finished with batch <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, taking a break<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Finished with batch \u001b[1;36m1\u001b[0m, taking a break\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Finished with batch <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, taking a break<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Finished with batch \u001b[1;36m2\u001b[0m, taking a break\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b31e7b9bf934a188ee2b4155cb13c88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████████████████████████████████████████████████████████████████████████████                                       | 2/3 [01:09<00:34, 34.91s/it]"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Finished with batch <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, taking a break<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Finished with batch \u001b[1;36m1\u001b[0m, taking a break\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Finished with batch <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, taking a break<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Finished with batch \u001b[1;36m2\u001b[0m, taking a break\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46a684c59d2e4efe9505528fa30da806",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [01:45<00:00, 35.07s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Total Time for Evaluation: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.75</span> minutes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Total Time for Evaluation: \u001b[1;36m1.75\u001b[0m minutes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = evaluation_harness(client.show_all_collections(), questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "ef934a28-8635-46f5-b016-9ea128012e4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Huberman_minilm_128\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Huberman_minilm_128\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'answer_correctness'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5986</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'answer_relevancy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9195</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'context_relevancy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2065</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'faithfulness'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8517</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[32m'answer_correctness'\u001b[0m: \u001b[1;36m0.5986\u001b[0m, \u001b[32m'answer_relevancy'\u001b[0m: \u001b[1;36m0.9195\u001b[0m, \u001b[32m'context_relevancy'\u001b[0m: \u001b[1;36m0.2065\u001b[0m, \u001b[32m'faithfulness'\u001b[0m: \u001b[1;36m0.8517\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">----------------------------------------------------------------------------------------------------\n",
       "</pre>\n"
      ],
      "text/plain": [
       "----------------------------------------------------------------------------------------------------\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Huberman_minilm_256\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Huberman_minilm_256\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'answer_correctness'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6522</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'answer_relevancy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8409</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'context_relevancy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1539</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'faithfulness'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9573</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[32m'answer_correctness'\u001b[0m: \u001b[1;36m0.6522\u001b[0m, \u001b[32m'answer_relevancy'\u001b[0m: \u001b[1;36m0.8409\u001b[0m, \u001b[32m'context_relevancy'\u001b[0m: \u001b[1;36m0.1539\u001b[0m, \u001b[32m'faithfulness'\u001b[0m: \u001b[1;36m0.9573\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">----------------------------------------------------------------------------------------------------\n",
       "</pre>\n"
      ],
      "text/plain": [
       "----------------------------------------------------------------------------------------------------\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Huberman_minilm_512\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Huberman_minilm_512\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'answer_correctness'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7298</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'answer_relevancy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9269</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'context_relevancy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1902</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'faithfulness'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9286</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[32m'answer_correctness'\u001b[0m: \u001b[1;36m0.7298\u001b[0m, \u001b[32m'answer_relevancy'\u001b[0m: \u001b[1;36m0.9269\u001b[0m, \u001b[32m'context_relevancy'\u001b[0m: \u001b[1;36m0.1902\u001b[0m, \u001b[32m'faithfulness'\u001b[0m: \u001b[1;36m0.9286\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">----------------------------------------------------------------------------------------------------\n",
       "</pre>\n"
      ],
      "text/plain": [
       "----------------------------------------------------------------------------------------------------\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bad pipe message: %s [b'\\xa2\\x00\\x97C\\xac\\xf2b\\xa4j\\x7f?@>n\\xd0\\xf6V\\x11 \\x15A\\x17K\\xb5\\xcd\\xa7B/\\xcf!y\\xc3\\xb6L)I(\\r\\xc8_\\x187\\x9a\\xa4\\xf9\\xb4\\xc2\\x1e.B\\x19\\x00\\x08\\x13\\x02\\x13\\x03\\x13\\x01\\x00\\xff\\x01\\x00\\x00\\x8f\\x00\\x00']\n",
      "Bad pipe message: %s [b'\\xf0\\x8b\\x91.&\\x07\\x11\\xf3\\x12\\x7fE\\xbb\\x9a/\\xe4Z\\xe5\\xcf \\xd7f\\xa0\\xac\"\\x8d\\t\\xdeF->%\\x18k\\xce\\xa7\\xde\\xec\\xee\\xa8\\xa1\\xb0\\xdc\\xba\\x8b\\xa3\\x13', b'sXo\\x00\\x08\\x13\\x02\\x13\\x03\\x13\\x01\\x00\\xff\\x01\\x00\\x00\\x8f\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x0c\\x00\\n\\x00\\x1d\\x00\\x17\\x00\\x1e\\x00\\x19\\x00\\x18\\x00#\\x00\\x00\\x00\\x16\\x00\\x00\\x00\\x17\\x00\\x00\\x00\\r\\x00\\x1e\\x00\\x1c\\x04\\x03\\x05\\x03\\x06\\x03\\x08\\x07\\x08\\x08\\x08\\t\\x08\\n\\x08\\x0b\\x08\\x04\\x08\\x05\\x08\\x06\\x04\\x01\\x05\\x01\\x06\\x01\\x00+\\x00\\x03\\x02\\x03\\x04\\x00-\\x00\\x02\\x01\\x01\\x003\\x00&\\x00$\\x00']\n",
      "Bad pipe message: %s [b' \\xae\\xdd\\x99\\x11\\xd8\\xa7(\\xe8\\x1e|v\\x92\\xe2\\x1e\\xf4\\xc6\\x00<\\xf5k\\xd0\\x9f\\xb8\\xc3\\x05s\\xd2']\n",
      "Bad pipe message: %s [b'\\xd7\\xa5\\xa5\\xdeo\\x96$\\x97\\r\\xae\\x9aQd\\xb1VY\\xb7\\x9f\\x00\\x00>\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\xc0\\x0f\\xc0\\x05\\x005\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00\\x96\\x00', b'\\x11\\xc0\\x07\\xc0\\x0c\\xc0']\n",
      "Bad pipe message: %s [b'\\x05']\n",
      "Bad pipe message: %s [b'\\r4a\\x87B1\\xa5\\x18\\xc0\\x87\\xfe\\xf3\\xc8\\x90*0\\xa1\\xf2\\x00\\x00\\xa2\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00:\\x00\\x89\\xc0\\x0f\\xc0\\x05\\x005\\x00\\x84\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00E\\x00D\\x00C\\x00B\\xc0\\x18\\x004\\x00\\x9b\\x00F\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x96\\x00A\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x16\\x00\\x18\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\xc0\\x12\\xc0\\x08\\x00\\x16\\x00\\x13\\x00\\x10\\x00\\r\\xc0\\x17\\x00\\x1b\\xc0\\r\\xc0\\x03\\x00\\n\\x00\\x15\\x00\\x12\\x00\\x0f\\x00\\x0c\\x00\\x1a\\x00\\t\\x00\\x14\\x00\\x11\\x00\\x19\\x00\\x08\\x00']\n",
      "Bad pipe message: %s [b'\\x17\\x00\\x03\\xc0\\x10']\n",
      "Bad pipe message: %s [b\"\\xe2l\\xd6\\xc5se\\xff'\\x8dR\\x13\\xb7:\\x1c5\\xb4{\\x9c\\x00\\x00\\xa2\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00:\\x00\\x89\\xc0\\x0f\\xc0\\x05\\x005\\x00\\x84\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00E\\x00D\\x00\", b'B\\xc0\\x18\\x004\\x00\\x9b\\x00F\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x96\\x00A\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x16\\x00\\x18\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\xc0\\x12\\xc0\\x08\\x00\\x16\\x00\\x13\\x00\\x10\\x00\\r\\xc0\\x17\\x00\\x1b\\xc0\\r\\xc0\\x03\\x00\\n\\x00\\x15\\x00\\x12\\x00\\x0f\\x00']\n",
      "Bad pipe message: %s [b'\\x1a\\x00\\t\\x00\\x14\\x00\\x11\\x00\\x19\\x00\\x08']\n",
      "Bad pipe message: %s [b'\\x95K1V\\x0bH^/l\\x8dz\\x97\\x139\\x1fv`\\x05\\x00\\x00\\xa2\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00:\\x00\\x89\\xc0\\x0f\\xc0']\n",
      "Bad pipe message: %s [b'5\\x00\\x84\\xc0']\n",
      "Bad pipe message: %s [b'\\t\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00']\n",
      "Bad pipe message: %s [b'D\\x00C\\x00B\\xc0\\x18\\x004\\x00\\x9b\\x00F\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x96\\x00A\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x16\\x00\\x18\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\xc0\\x12\\xc0\\x08\\x00\\x16\\x00\\x13\\x00\\x10\\x00\\r\\xc0\\x17\\x00\\x1b\\xc0\\r\\xc0\\x03\\x00\\n\\x00\\x15\\x00\\x12\\x00']\n",
      "Bad pipe message: %s [b'\\x0c\\x00\\x1a\\x00\\t\\x00\\x14\\x00\\x11\\x00\\x19\\x00\\x08\\x00']\n",
      "Bad pipe message: %s [b'\\x17\\x00\\x03\\xc0\\x10']\n",
      "Bad pipe message: %s [b\"=\\x0e}2R!\\xbe=\\xcaL\\xed\\xbbm\\x02\\xa2M\\x00>\\x00\\x00\\x86\\xc00\\xc0,\\xc0(\\xc0$\\xc0\\x14\\xc0\\n\\x00\\xa5\\x00\\xa3\\x00\\xa1\\x00\\x9f\\x00k\\x00j\\x00i\\x00h\\x009\\x008\\x007\\x006\\xc02\\xc0.\\xc0*\\xc0&\\xc0\\x0f\\xc0\\x05\\x00\\x9d\\x00=\\x005\\xc0/\\xc0+\\xc0'\\xc0#\\xc0\\x13\\xc0\\t\\x00\\xa4\\x00\\xa2\\x00\\xa0\\x00\\x9e\\x00g\\x00@\\x00?\\x00>\\x003\\x002\\x001\\x000\\xc01\\xc0-\\xc0)\\xc0%\\xc0\\x0e\\xc0\\x04\\x00\\x9c\\x00<\\x00/\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00\\x96\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\x00\\xff\\x02\\x01\\x00\\x00g\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x1c\\x00\\x1a\\x00\\x17\\x00\\x19\\x00\\x1c\\x00\\x1b\\x00\\x18\\x00\\x1a\\x00\\x16\\x00\\x0e\\x00\\r\\x00\\x0b\\x00\\x0c\\x00\\t\\x00\\n\\x00#\\x00\\x00\\x00\\r\\x00 \\x00\\x1e\\x06\\x01\\x06\\x02\\x06\\x03\\x05\\x01\\x05\\x02\\x05\\x03\\x04\\x01\\x04\\x02\\x04\\x03\\x03\\x01\\x03\\x02\\x03\"]\n",
      "Bad pipe message: %s [b'\\x01\\x02']\n",
      "Bad pipe message: %s [b'\\x03']\n",
      "Bad pipe message: %s [b\"x\\x06,91\\xd5\\xe8\\x87,@\\xec6\\xa2\\x07,\\xbd\\xa3,\\x00\\x00\\xf4\\xc00\\xc0,\\xc0(\\xc0$\\xc0\\x14\\xc0\\n\\x00\\xa5\\x00\\xa3\\x00\\xa1\\x00\\x9f\\x00k\\x00j\\x00i\\x00h\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00\\xa7\\x00m\\x00:\\x00\\x89\\xc02\\xc0.\\xc0*\\xc0&\\xc0\\x0f\\xc0\\x05\\x00\\x9d\\x00=\\x005\\x00\\x84\\xc0/\\xc0+\\xc0'\\xc0#\\xc0\\x13\\xc0\\t\\x00\\xa4\\x00\\xa2\\x00\\xa0\\x00\\x9e\\x00g\\x00@\\x00?\\x00>\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00E\\x00D\\x00C\\x00B\\xc0\\x18\\x00\\xa6\\x00l\\x004\\x00\\x9b\\x00F\\xc01\\xc0-\\xc0)\\xc0%\\xc0\\x0e\\xc0\\x04\\x00\", b'<\\x00/\\x00\\x96\\x00A\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x16\\x00\\x18\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\xc0\\x12\\xc0\\x08\\x00\\x16\\x00\\x13\\x00\\x10\\x00\\r\\xc0\\x17\\x00\\x1b\\xc0\\r\\xc0\\x03\\x00\\n\\x00\\x15\\x00\\x12\\x00\\x0f\\x00\\x0c\\x00\\x1a\\x00\\t\\x00\\x14\\x00\\x11\\x00\\x19\\x00\\x08\\x00\\x06\\x00\\x17\\x00\\x03\\xc0\\x10\\xc0\\x06\\xc0\\x15\\xc0\\x0b\\xc0\\x01\\x00;\\x00\\x02\\x00\\x01\\x00\\xff\\x02\\x01\\x00\\x00g\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x1c\\x00\\x1a\\x00\\x17\\x00\\x19\\x00\\x1c\\x00\\x1b\\x00\\x18\\x00\\x1a\\x00\\x16\\x00\\x0e\\x00\\r\\x00\\x0b\\x00\\x0c\\x00\\t\\x00\\n\\x00']\n",
      "Bad pipe message: %s [b'\\x00\\x00\\r\\x00 \\x00\\x1e\\x06\\x01\\x06\\x02\\x06\\x03\\x05\\x01\\x05\\x02\\x05\\x03\\x04\\x01\\x04\\x02\\x04\\x03\\x03\\x01\\x03\\x02\\x03\\x03\\x02\\x01\\x02']\n",
      "Bad pipe message: %s [b'\\x03']\n"
     ]
    }
   ],
   "source": [
    "for k, v in sorted(results.items()):\n",
    "    print(k)\n",
    "    print(v)\n",
    "    print('-'*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "efd69269-eb4b-4a7a-87d9-560e0581295b",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [answer_correctness, answer_relevancy, context_relevancy, faithfulness]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "0b7ceba7-f47a-4116-b7a2-d097186251ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa2a843f858743cd8455e669ba076961",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_512 = evaluate(dataset, metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "5bb5828a-8bcc-4272-a518-6485c52deaf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer_correctness': 0.7425, 'answer_relevancy': 0.9382, 'context_relevancy': 0.2418, 'faithfulness': 0.9600}"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "1dfd3709-58c2-4bde-85d3-a0f35db43f43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer_correctness': 0.5783, 'answer_relevancy': 0.9028, 'context_relevancy': 0.3534, 'faithfulness': 0.9100}"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "c9f36500-f90d-45b1-8920-7244b260dbba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer_correctness': 0.6315, 'answer_relevancy': 0.9385, 'context_relevancy': 0.1621, 'faithfulness': 1.0000}"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threaded_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "77a5005b-bafb-4c85-a537-43f34bf81810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer_correctness': 0.6432, 'answer_relevancy': 0.9236, 'context_relevancy': 0.1621, 'faithfulness': 1.0000}"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "turbo_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "14ddce00-4410-4f38-bba0-902c79849a99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer_correctness': 0.6332, 'answer_relevancy': 0.9271, 'context_relevancy': 0.1621, 'faithfulness': 1.0000}"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "turbo_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "14847f1b-41d5-4e66-9030-a439179808e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = 'What does Huberman recommend for a morning routine'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "e0ef78ab-034d-4459-9baa-639b6b4fcc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_name = 'Huberman_minilm_256'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "5a0f9ed1-db0f-4e08-a911-435dac37b9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = []\n",
    "for q in questions:\n",
    "    context = client.hybrid_search(q, collection_name, \n",
    "                                   query_properties=['content', 'title', 'short_description'],\n",
    "                                   limit=3, \n",
    "                                   return_properties=['content', 'guest', 'short_description'])\n",
    "    #generate assistant message prompt\n",
    "    assist_message = generate_prompt_series(q, context, summary_key='short_description')\n",
    "    combined = huberman_system_prompt + ' ' + assist_message\n",
    "    counts.append(get_token_count(combined))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "8aba91c3-cf58-4204-b93c-3a5eaae6d903",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500000"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_tokens = 5000 * 100\n",
    "total_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "951d51f8-7a6c-45e4-aaca-e812a76e43d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "output, input = 50000, 450000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "74ad489f-1b36-4746-8c90-1eef9ff471c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.075"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_price = (1.5/1000000) * output\n",
    "output_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "5cf6b9e4-68ac-4cbf-ad84-0cc96decaa60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22499999999999998"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_price = (0.50/1000000) * input\n",
    "input_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "176e7ae3-9952-419b-b629-9331ff411e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_gpt35 = output_price + input_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "d69e91dd-39ac-4f72-930d-b2c355a5316e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.0"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "turbo4_output_price = (30/1000000) * output\n",
    "turbo4_input_price = (10/1000000) * input\n",
    "total_gpt4_price = turbo4_input_price + turbo4_output_price\n",
    "total_gpt4_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "ba6da881-4d33-4b6c-a955-f1b84096fb00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.725"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hybrid_price = input_price + turbo4_output_price\n",
    "hybrid_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ae959a-08b6-4f42-a986-c85cc30ab83a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "openai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
